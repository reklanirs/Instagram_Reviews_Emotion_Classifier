{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instagram Positive Negative.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reklanirs/Instagram_Reviews_Emotion_Classifier/blob/main/Instagram_Positive_Negative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx6ll8shnv1T",
        "outputId": "6393841c-8836-45a7-ab91-bf4e0d09ec52"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 18.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 18.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 71kB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 40.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 35.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 56.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 57.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.4MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwwOlOZ1sJ82"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SNEVEkTofmc"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optmizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVvhgJK1ozCW",
        "outputId": "ec00562d-afa3-4320-af8c-f9efa2e5ef94"
      },
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdVeUwTvpBhr",
        "outputId": "6fe564a3-8674-4bfc-8992-d5fe67666755"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mLYbsh-pSFP",
        "outputId": "535f3844-e17f-41c5-9ee1-7e4cbd6a402b"
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label} ({class_names[label]})')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
            "Label : 0 (neg)\n",
            "Review: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
            "Label : 0 (neg)\n",
            "Review: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
            "Label : 1 (pos)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS_p_sf8sxEe",
        "outputId": "c11458fb-d358-41ae-f347-378b32778018"
      },
      "source": [
        "bert_model_name = 'albert_en_base' \n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/albert_en_base/2\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/albert_en_preprocess/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLvmq1WmuM-2"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FkZ0TN-uTCr",
        "outputId": "2e1db58c-08c2-4599-b1a5-f7ef3617d46b"
      },
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [   2   48   25  145   40 5289 1308  187    3    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhAwzFQJup8q",
        "outputId": "813b1dab-162a-4144-c73e-3afe64e348a1"
      },
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/albert_en_base/2\n",
            "Pooled Outputs Shape:(1, 768)\n",
            "Pooled Outputs Values:[ 0.5642009  -0.58338153  0.89203125 -0.88340575 -0.5900787  -0.97489256\n",
            "  0.59733707 -0.565075    0.6582608  -0.999905    0.92247003  0.5789065 ]\n",
            "Sequence Outputs Shape:(1, 128, 768)\n",
            "Sequence Outputs Values:[[ 0.9379119   0.28509057 -0.37701207 ...  0.19407773 -1.1221735\n",
            "   0.5021104 ]\n",
            " [ 1.6732261  -1.259339    0.98551273 ... -0.03488621  2.440246\n",
            "  -1.4151798 ]\n",
            " [ 1.5726185  -0.7276678  -0.61325175 ...  1.1369412  -0.24407259\n",
            "  -0.20238948]\n",
            " ...\n",
            " [ 0.46375355  0.78065187 -0.00772711 ...  0.36924443  0.9916427\n",
            "  -1.1032648 ]\n",
            " [ 0.44642958  0.8588988   0.020445   ...  0.4076947   1.0863223\n",
            "  -1.0217936 ]\n",
            " [ 0.46782312  0.8818837   0.02625137 ...  0.4404548   1.1098762\n",
            "  -1.0167123 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVRQWFQSxTtG"
      },
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIsABNN9xWe2",
        "outputId": "6682200c-554e-4008-a315-05ba140a50b6"
      },
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.33691]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S13aqxBLyVGz"
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJRu21Qxya0M"
      },
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 2e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "checkpoint_path = \"saved/training/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=1*batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBUeWn1h11tg"
      },
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCB1LpAg16Fy",
        "outputId": "425f3d30-b3fb-4c01-c691-f9418eb7bdb3"
      },
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds,\n",
        "                               validation_data=val_ds,\n",
        "                               batch_size=batch_size,\n",
        "                               epochs=epochs,\n",
        "                               callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/albert_en_base/2\n",
            "Epoch 1/5\n",
            " 32/625 [>.............................] - ETA: 12:38 - loss: 0.7083 - binary_accuracy: 0.5343\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            " 64/625 [==>...........................] - ETA: 11:41 - loss: 0.7110 - binary_accuracy: 0.5310\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            " 96/625 [===>..........................] - ETA: 11:04 - loss: 0.7022 - binary_accuracy: 0.5403\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "128/625 [=====>........................] - ETA: 10:22 - loss: 0.6841 - binary_accuracy: 0.5585\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "160/625 [======>.......................] - ETA: 9:42 - loss: 0.6630 - binary_accuracy: 0.5784\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "192/625 [========>.....................] - ETA: 9:02 - loss: 0.6429 - binary_accuracy: 0.5969\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "224/625 [=========>....................] - ETA: 8:22 - loss: 0.6256 - binary_accuracy: 0.6130\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "256/625 [===========>..................] - ETA: 7:42 - loss: 0.6096 - binary_accuracy: 0.6274\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "288/625 [============>.................] - ETA: 7:02 - loss: 0.5950 - binary_accuracy: 0.6402\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "320/625 [==============>...............] - ETA: 6:22 - loss: 0.5821 - binary_accuracy: 0.6514\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "352/625 [===============>..............] - ETA: 5:42 - loss: 0.5704 - binary_accuracy: 0.6613\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "384/625 [=================>............] - ETA: 5:02 - loss: 0.5601 - binary_accuracy: 0.6700\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "416/625 [==================>...........] - ETA: 4:21 - loss: 0.5505 - binary_accuracy: 0.6780\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "448/625 [====================>.........] - ETA: 3:41 - loss: 0.5417 - binary_accuracy: 0.6853\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "480/625 [======================>.......] - ETA: 3:01 - loss: 0.5335 - binary_accuracy: 0.6921\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "512/625 [=======================>......] - ETA: 2:21 - loss: 0.5259 - binary_accuracy: 0.6984\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "544/625 [=========================>....] - ETA: 1:41 - loss: 0.5189 - binary_accuracy: 0.7041\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "576/625 [==========================>...] - ETA: 1:01 - loss: 0.5125 - binary_accuracy: 0.7093\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "608/625 [============================>.] - ETA: 21s - loss: 0.5065 - binary_accuracy: 0.7142\n",
            "Epoch 00001: saving model to saved/training/cp-0001.ckpt\n",
            "625/625 [==============================] - 850s 1s/step - loss: 0.5034 - binary_accuracy: 0.7167 - val_loss: 0.3000 - val_binary_accuracy: 0.8788\n",
            "Epoch 2/5\n",
            " 15/625 [..............................] - ETA: 12:32 - loss: 0.3219 - binary_accuracy: 0.8598\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            " 47/625 [=>............................] - ETA: 11:57 - loss: 0.3121 - binary_accuracy: 0.8595\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            " 79/625 [==>...........................] - ETA: 11:20 - loss: 0.3085 - binary_accuracy: 0.8607\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "111/625 [====>.........................] - ETA: 10:41 - loss: 0.3062 - binary_accuracy: 0.8619\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "143/625 [=====>........................] - ETA: 10:01 - loss: 0.3037 - binary_accuracy: 0.8639\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "175/625 [=======>......................] - ETA: 9:22 - loss: 0.3019 - binary_accuracy: 0.8655\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "207/625 [========>.....................] - ETA: 8:42 - loss: 0.3005 - binary_accuracy: 0.8669\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "239/625 [==========>...................] - ETA: 8:02 - loss: 0.2993 - binary_accuracy: 0.8681\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "271/625 [============>.................] - ETA: 7:22 - loss: 0.2973 - binary_accuracy: 0.8695\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "303/625 [=============>................] - ETA: 6:42 - loss: 0.2956 - binary_accuracy: 0.8707\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "335/625 [===============>..............] - ETA: 6:02 - loss: 0.2936 - binary_accuracy: 0.8719\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "367/625 [================>.............] - ETA: 5:22 - loss: 0.2919 - binary_accuracy: 0.8730\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "399/625 [==================>...........] - ETA: 4:42 - loss: 0.2901 - binary_accuracy: 0.8742\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "431/625 [===================>..........] - ETA: 4:02 - loss: 0.2881 - binary_accuracy: 0.8754\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "463/625 [=====================>........] - ETA: 3:22 - loss: 0.2861 - binary_accuracy: 0.8765\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "495/625 [======================>.......] - ETA: 2:42 - loss: 0.2843 - binary_accuracy: 0.8776\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "527/625 [========================>.....] - ETA: 2:02 - loss: 0.2824 - binary_accuracy: 0.8787\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "559/625 [=========================>....] - ETA: 1:22 - loss: 0.2806 - binary_accuracy: 0.8798\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "591/625 [===========================>..] - ETA: 42s - loss: 0.2789 - binary_accuracy: 0.8807\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "623/625 [============================>.] - ETA: 2s - loss: 0.2774 - binary_accuracy: 0.8816\n",
            "Epoch 00002: saving model to saved/training/cp-0002.ckpt\n",
            "625/625 [==============================] - 840s 1s/step - loss: 0.2772 - binary_accuracy: 0.8817 - val_loss: 0.2987 - val_binary_accuracy: 0.8840\n",
            "Epoch 3/5\n",
            " 30/625 [>.............................] - ETA: 12:17 - loss: 0.2135 - binary_accuracy: 0.9270\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            " 62/625 [=>............................] - ETA: 11:42 - loss: 0.2115 - binary_accuracy: 0.9212\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            " 94/625 [===>..........................] - ETA: 11:04 - loss: 0.2084 - binary_accuracy: 0.9199\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "126/625 [=====>........................] - ETA: 10:24 - loss: 0.2053 - binary_accuracy: 0.9202\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "158/625 [======>.......................] - ETA: 9:44 - loss: 0.2035 - binary_accuracy: 0.9209\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "190/625 [========>.....................] - ETA: 9:04 - loss: 0.2020 - binary_accuracy: 0.9216\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "222/625 [=========>....................] - ETA: 8:24 - loss: 0.2004 - binary_accuracy: 0.9224\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "254/625 [===========>..................] - ETA: 7:44 - loss: 0.1988 - binary_accuracy: 0.9232\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "286/625 [============>.................] - ETA: 7:04 - loss: 0.1978 - binary_accuracy: 0.9238\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "318/625 [==============>...............] - ETA: 6:24 - loss: 0.1965 - binary_accuracy: 0.9244\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "350/625 [===============>..............] - ETA: 5:44 - loss: 0.1951 - binary_accuracy: 0.9252\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "382/625 [=================>............] - ETA: 5:04 - loss: 0.1940 - binary_accuracy: 0.9259\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "414/625 [==================>...........] - ETA: 4:24 - loss: 0.1926 - binary_accuracy: 0.9267\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "446/625 [====================>.........] - ETA: 3:44 - loss: 0.1910 - binary_accuracy: 0.9275\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "478/625 [=====================>........] - ETA: 3:04 - loss: 0.1895 - binary_accuracy: 0.9283\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "510/625 [=======================>......] - ETA: 2:24 - loss: 0.1880 - binary_accuracy: 0.9291\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "542/625 [=========================>....] - ETA: 1:44 - loss: 0.1865 - binary_accuracy: 0.9299\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "574/625 [==========================>...] - ETA: 1:03 - loss: 0.1851 - binary_accuracy: 0.9306\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "606/625 [============================>.] - ETA: 23s - loss: 0.1837 - binary_accuracy: 0.9312\n",
            "Epoch 00003: saving model to saved/training/cp-0003.ckpt\n",
            "625/625 [==============================] - 841s 1s/step - loss: 0.1829 - binary_accuracy: 0.9316 - val_loss: 0.4330 - val_binary_accuracy: 0.8798\n",
            "Epoch 4/5\n",
            " 13/625 [..............................] - ETA: 12:39 - loss: 0.1389 - binary_accuracy: 0.9604\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            " 45/625 [=>............................] - ETA: 12:04 - loss: 0.1312 - binary_accuracy: 0.9579\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            " 77/625 [==>...........................] - ETA: 11:26 - loss: 0.1262 - binary_accuracy: 0.9590\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "109/625 [====>.........................] - ETA: 10:46 - loss: 0.1222 - binary_accuracy: 0.9600\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "141/625 [=====>........................] - ETA: 10:07 - loss: 0.1188 - binary_accuracy: 0.9609\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "173/625 [=======>......................] - ETA: 9:27 - loss: 0.1174 - binary_accuracy: 0.9612\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "205/625 [========>.....................] - ETA: 8:47 - loss: 0.1159 - binary_accuracy: 0.9617\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "237/625 [==========>...................] - ETA: 8:07 - loss: 0.1147 - binary_accuracy: 0.9620\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "269/625 [===========>..................] - ETA: 7:26 - loss: 0.1135 - binary_accuracy: 0.9624\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "301/625 [=============>................] - ETA: 6:46 - loss: 0.1122 - binary_accuracy: 0.9628\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "333/625 [==============>...............] - ETA: 6:06 - loss: 0.1108 - binary_accuracy: 0.9634\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "365/625 [================>.............] - ETA: 5:25 - loss: 0.1097 - binary_accuracy: 0.9638\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "397/625 [==================>...........] - ETA: 4:45 - loss: 0.1087 - binary_accuracy: 0.9643\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "429/625 [===================>..........] - ETA: 4:05 - loss: 0.1077 - binary_accuracy: 0.9648\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "461/625 [=====================>........] - ETA: 3:25 - loss: 0.1067 - binary_accuracy: 0.9653\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "493/625 [======================>.......] - ETA: 2:45 - loss: 0.1060 - binary_accuracy: 0.9657\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "525/625 [========================>.....] - ETA: 2:05 - loss: 0.1052 - binary_accuracy: 0.9661\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "557/625 [=========================>....] - ETA: 1:25 - loss: 0.1044 - binary_accuracy: 0.9665\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "589/625 [===========================>..] - ETA: 45s - loss: 0.1038 - binary_accuracy: 0.9669\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "621/625 [============================>.] - ETA: 5s - loss: 0.1032 - binary_accuracy: 0.9672\n",
            "Epoch 00004: saving model to saved/training/cp-0004.ckpt\n",
            "625/625 [==============================] - 841s 1s/step - loss: 0.1031 - binary_accuracy: 0.9672 - val_loss: 0.5972 - val_binary_accuracy: 0.8808\n",
            "Epoch 5/5\n",
            " 28/625 [>.............................] - ETA: 12:19 - loss: 0.1012 - binary_accuracy: 0.9811\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            " 60/625 [=>............................] - ETA: 11:45 - loss: 0.0847 - binary_accuracy: 0.9797\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            " 92/625 [===>..........................] - ETA: 11:06 - loss: 0.0776 - binary_accuracy: 0.9799\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "124/625 [====>.........................] - ETA: 10:27 - loss: 0.0723 - binary_accuracy: 0.9803\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "156/625 [======>.......................] - ETA: 9:47 - loss: 0.0697 - binary_accuracy: 0.9805\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "188/625 [========>.....................] - ETA: 9:07 - loss: 0.0683 - binary_accuracy: 0.9807\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "220/625 [=========>....................] - ETA: 8:27 - loss: 0.0671 - binary_accuracy: 0.9810\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "252/625 [===========>..................] - ETA: 7:47 - loss: 0.0661 - binary_accuracy: 0.9812\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "284/625 [============>.................] - ETA: 7:07 - loss: 0.0652 - binary_accuracy: 0.9815\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "316/625 [==============>...............] - ETA: 6:27 - loss: 0.0641 - binary_accuracy: 0.9819\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "348/625 [===============>..............] - ETA: 5:47 - loss: 0.0630 - binary_accuracy: 0.9823\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "380/625 [=================>............] - ETA: 5:07 - loss: 0.0621 - binary_accuracy: 0.9826\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "412/625 [==================>...........] - ETA: 4:27 - loss: 0.0612 - binary_accuracy: 0.9829\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "444/625 [====================>.........] - ETA: 3:46 - loss: 0.0604 - binary_accuracy: 0.9832\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "476/625 [=====================>........] - ETA: 3:06 - loss: 0.0596 - binary_accuracy: 0.9835\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "508/625 [=======================>......] - ETA: 2:26 - loss: 0.0590 - binary_accuracy: 0.9838\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "540/625 [========================>.....] - ETA: 1:46 - loss: 0.0584 - binary_accuracy: 0.9840\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "572/625 [==========================>...] - ETA: 1:06 - loss: 0.0579 - binary_accuracy: 0.9843\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "604/625 [===========================>..] - ETA: 26s - loss: 0.0575 - binary_accuracy: 0.9845\n",
            "Epoch 00005: saving model to saved/training/cp-0005.ckpt\n",
            "625/625 [==============================] - 841s 1s/step - loss: 0.0572 - binary_accuracy: 0.9846 - val_loss: 0.6175 - val_binary_accuracy: 0.8852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAwULa1gJqTD"
      },
      "source": [
        "classifier_model.save_weights('./saved/my_checkpoint')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfS2RuSnJxCO",
        "outputId": "39d0c78a-6ec4-4479-cbe7-fa7d2d5a0c62"
      },
      "source": [
        "classifier_model.save('saved/classifier_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 85). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 85). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKeSytOKKCBo",
        "outputId": "5d7d1806-9d62-4499-d30c-4d26409de4b1"
      },
      "source": [
        "loss, accuracy = classifier_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 287s 367ms/step - loss: 0.6110 - binary_accuracy: 0.8870\n",
            "Loss: 0.6110113263130188\n",
            "Accuracy: 0.8869600296020508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "7jJgGY44RAOo",
        "outputId": "51a5e8eb-8f3f-4439-b90d-bb613addb424"
      },
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f108dd0f450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cfjWrcGzXEM",
        "outputId": "da6cf2ab-70e7-4b84-a7a6-f42a0e67fb1f"
      },
      "source": [
        "reloaded_model = build_classifier_model()\n",
        "reloaded_model.load_weights(\"saved/training/cp-0002.ckpt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1081d353d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "OYWMCRvF32-u",
        "outputId": "541d333d-6209-428a-da24-0f03fd53cc6a"
      },
      "source": [
        "reloaded_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n",
        "loss, accuracy = reloaded_model.evaluate(test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-88f5ca4b5dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                          metrics=metrics)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1186 test_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:186 __call__\n        self.build(y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:139 build\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:659 map_structure\n        structure[0], [func(*x) for x in entries],\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:659 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:262 _get_loss_object\n        loss = losses_mod.get(loss)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1906 get\n        'Could not interpret loss function identifier: {}'.format(identifier))\n\n    ValueError: Could not interpret loss function identifier: 0.6110113263130188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ooxGeDiRSXH",
        "outputId": "5274771c-7f66-4466-bec4-ac3b6107db66"
      },
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "  \n",
        "examples = [\n",
        "    'this is such an amazing movie!',  # this is the same sentence tried earlier\n",
        "    'The movie was great!',\n",
        "    'The movie was meh.',\n",
        "    'The movie was okish.',\n",
        "    'The movie was terrible...'\n",
        "]\n",
        "\n",
        "\n",
        "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
        "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
        "\n",
        "print('Results from the reloaded model:')\n",
        "print_my_examples(examples, reloaded_results)\n",
        "print('Results from the model in memory:')\n",
        "print_my_examples(examples, original_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results from the reloaded model:\n",
            "input: this is such an amazing movie! : score: 0.996032\n",
            "input: The movie was great!           : score: 0.993145\n",
            "input: The movie was meh.             : score: 0.196019\n",
            "input: The movie was okish.           : score: 0.110063\n",
            "input: The movie was terrible...      : score: 0.007697\n",
            "\n",
            "Results from the model in memory:\n",
            "input: this is such an amazing movie! : score: 0.998181\n",
            "input: The movie was great!           : score: 0.998981\n",
            "input: The movie was meh.             : score: 0.000993\n",
            "input: The movie was okish.           : score: 0.222768\n",
            "input: The movie was terrible...      : score: 0.000417\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLWvAEwJT-My"
      },
      "source": [
        "lines_dataset = tf.data.TextLineDataset(str(myfile))\n",
        "print(next(iter(lines_dataset.take(1))))\n",
        "results = tf.sigmoid(classifier_model.predict(lines_dataset.batch(batch_size)))\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhlEqvg90aHd",
        "outputId": "4cd638c0-9877-43ff-9f5e-8e97f369df4b"
      },
      "source": [
        "results2 = tf.sigmoid(reloaded_model.predict(lines_dataset.batch(batch_size)))\n",
        "print(results2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.38691592]\n",
            " [0.8024806 ]\n",
            " [0.7709689 ]\n",
            " [0.6500438 ]\n",
            " [0.3182437 ]\n",
            " [0.6506537 ]\n",
            " [0.99548125]\n",
            " [0.3402478 ]\n",
            " [0.6667965 ]\n",
            " [0.2605272 ]\n",
            " [0.4939794 ]\n",
            " [0.83960384]\n",
            " [0.4825674 ]\n",
            " [0.11023054]\n",
            " [0.36007184]\n",
            " [0.35629943]\n",
            " [0.64960307]\n",
            " [0.38863042]\n",
            " [0.77261174]\n",
            " [0.35791388]\n",
            " [0.53954065]\n",
            " [0.44354144]\n",
            " [0.18393888]\n",
            " [0.8317018 ]\n",
            " [0.81395537]\n",
            " [0.7049404 ]\n",
            " [0.76845384]\n",
            " [0.6313524 ]\n",
            " [0.19739114]\n",
            " [0.92112064]\n",
            " [0.7905381 ]\n",
            " [0.56744707]\n",
            " [0.6016736 ]\n",
            " [0.09547912]\n",
            " [0.23292476]\n",
            " [0.35812142]\n",
            " [0.70058316]\n",
            " [0.7818396 ]\n",
            " [0.4118118 ]\n",
            " [0.6277979 ]\n",
            " [0.8067163 ]\n",
            " [0.757319  ]\n",
            " [0.71468794]\n",
            " [0.7550943 ]\n",
            " [0.33279222]\n",
            " [0.66867167]\n",
            " [0.7819685 ]\n",
            " [0.40791705]\n",
            " [0.34524146]\n",
            " [0.81113225]\n",
            " [0.43421897]\n",
            " [0.6342496 ]\n",
            " [0.59536934]\n",
            " [0.704869  ]\n",
            " [0.71737164]\n",
            " [0.6606587 ]\n",
            " [0.74829197]\n",
            " [0.23277506]\n",
            " [0.65094024]\n",
            " [0.5250279 ]\n",
            " [0.85411775]\n",
            " [0.8355744 ]\n",
            " [0.7209844 ]\n",
            " [0.18108663]\n",
            " [0.5508997 ]\n",
            " [0.4461097 ]\n",
            " [0.5859261 ]\n",
            " [0.5020758 ]\n",
            " [0.64052826]\n",
            " [0.5023001 ]\n",
            " [0.69066066]\n",
            " [0.7260606 ]\n",
            " [0.21809307]\n",
            " [0.09892064]\n",
            " [0.4546096 ]\n",
            " [0.81523204]\n",
            " [0.20194182]\n",
            " [0.9206068 ]\n",
            " [0.44695678]\n",
            " [0.20194182]\n",
            " [0.7277159 ]\n",
            " [0.7206483 ]\n",
            " [0.59496176]\n",
            " [0.47616628]\n",
            " [0.75622797]\n",
            " [0.5781457 ]\n",
            " [0.8014399 ]\n",
            " [0.11204439]\n",
            " [0.6651385 ]\n",
            " [0.23410626]\n",
            " [0.12925805]\n",
            " [0.58368397]\n",
            " [0.6527636 ]\n",
            " [0.41536868]\n",
            " [0.30110058]\n",
            " [0.44549435]\n",
            " [0.5266628 ]\n",
            " [0.398528  ]\n",
            " [0.640216  ]\n",
            " [0.55549246]], shape=(100, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNUHVHsj0msa",
        "outputId": "953e3f7a-9021-4e6c-ac0a-044ceb54b93f"
      },
      "source": [
        "results2[0].numpy()[0]\n",
        "next(lines_dataset.as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Heyy..i just wanted to know the price and if the top third one(gucci) is available for airpods 1/2?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSnCYpfo0gnT"
      },
      "source": [
        "with open('output.txt', 'w') as fout:\n",
        "  for i,j in zip(lines_dataset.as_numpy_iterator(), results2):\n",
        "    # fout.write(f'{i},{j.numpy()[0]}\\n')\n",
        "    fout.write(f'{round(j.numpy()[0])},{j.numpy()[0]:.03f},{i.decode(\"utf-8\").replace(\",\",\"\")}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}